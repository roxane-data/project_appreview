{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0780dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import re\n",
    "import emoji #install pip install emoji --upgrade\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d20cc0",
   "metadata": {},
   "source": [
    "# Phase 0 => Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d5f51",
   "metadata": {},
   "source": [
    "Creation of new dataset to run classification model with only 2 dimensions : 'review content' and 'rating'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce107c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = df[['review_content','rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157493c5",
   "metadata": {},
   "source": [
    "### A) Label creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf4e8e",
   "metadata": {},
   "source": [
    "Since the dataset is inbalanced, 2 scenarii need to be designed depending on the success of ML prediction :\n",
    "- 1 scenario with 5 categories corresponding to the 5 different scores (from 1 to 5)\n",
    "- 1 scenario with 3 macro-categories gathering scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622adda",
   "metadata": {},
   "source": [
    "##### Scenario 1 => 5 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function creating labels accroding to rating\n",
    "def label_rating (row):\n",
    "    if row['rating'] == 1 :\n",
    "        return '1 - awful'\n",
    "    if row['rating'] == 2 :\n",
    "        return '2 - bad'\n",
    "    if row['rating'] == 3 :\n",
    "        return '3 - neutral'\n",
    "    if row['rating'] == 4 :\n",
    "        return '4 - good'\n",
    "    if row['rating'] == 5 :\n",
    "        return '5 - awesome'\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395259f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application of function to create labels\n",
    "df_test1['rating_label'] = df_test1.apply (lambda row: label_rating(row), axis=1)\n",
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f16623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of dictionary scenario 1\n",
    "rating1_df = df_test1[['rating_label', 'rating']].drop_duplicates().sort_values('rating')\n",
    "ratinglabel1_to_id = dict(rating1_df.values)\n",
    "id_to_ratinglabel1 = dict(rating1_df[['rating', 'rating_label']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratinglabel1_to_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c80c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution chart\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df_test1.groupby('rating_label').review_content.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4a53c",
   "metadata": {},
   "source": [
    "##### Scenario 2 => 3 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25baff49",
   "metadata": {},
   "source": [
    "- Bad = categories 1 & 2\n",
    "- Neutral = category 3\n",
    "- Good = categories 4 & 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f78fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df[['review_content','rating']]\n",
    "\n",
    "def label_rating2 (row):\n",
    "    if row['rating'] == 1 :\n",
    "        return 'bad'\n",
    "    if row['rating'] == 2 :\n",
    "        return 'bad'\n",
    "    if row['rating'] == 3 :\n",
    "        return 'neutral'\n",
    "    if row['rating'] == 4 :\n",
    "        return 'good'\n",
    "    if row['rating'] == 5 :\n",
    "        return 'good'\n",
    "    return 'Other'\n",
    "\n",
    "df_test2['rating_label'] = df_test2.apply (lambda row: label_rating2(row), axis=1)\n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of dictionary scenario 2\n",
    "rating2_df = df_test2[['rating_label', 'rating']].drop_duplicates().sort_values('rating')\n",
    "ratinglabel2_to_id = dict(rating2_df.values)\n",
    "id_to_ratinglabel2 = dict(rating2_df[['rating', 'rating_label']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution chart\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df_test2.groupby('rating_label').review_content.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806706b5",
   "metadata": {},
   "source": [
    "# Phase 1 => Preparatory work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd73c1b",
   "metadata": {},
   "source": [
    "### A) Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b4d526",
   "metadata": {},
   "source": [
    "#### Step 1 => Features created directly from text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad7369e",
   "metadata": {},
   "source": [
    "1. Number of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c96bb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chars(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4393b8",
   "metadata": {},
   "source": [
    "2. Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78ff6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e573ac",
   "metadata": {},
   "source": [
    "3. Number of capital characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b18dbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_capital_chars(text):\n",
    "    count=0\n",
    "    for i in text:\n",
    "        if i.isupper()== True: #isupper() method returns: True if characters in a string are uppercase characters\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe3024",
   "metadata": {},
   "source": [
    "4. Number of capital words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b56e469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_capital_words(text):\n",
    "    return sum(map(str.isupper, text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417bebb6",
   "metadata": {},
   "source": [
    "5. Count the number of punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4a56cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuations(text):\n",
    "    punctuations=\"!#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    d=dict()\n",
    "    for i in punctuations:\n",
    "        d[str(i)+'count']=text.count(i)\n",
    "    return d "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f6619",
   "metadata": {},
   "source": [
    "6. Number of words in quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a6bf0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_quotes(text):\n",
    "    x = re.findall(\"'.'|'.'\", text)\n",
    "    count=0\n",
    "    if x is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in x:\n",
    "            t=i[1:-1]\n",
    "            count+=count_words(t)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5708",
   "metadata": {},
   "source": [
    "7. Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7df8ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sent(text):\n",
    "    return len(nltk.sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e143fbf",
   "metadata": {},
   "source": [
    "8. Count the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23fa16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_words(text):\n",
    "    return len(set(text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbb1cb",
   "metadata": {},
   "source": [
    "9. Count of hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a5784da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_htags(text):\n",
    "    x = re.findall(r'(#w[A-Za-z0-9]*)', text)\n",
    "    return len(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde5981",
   "metadata": {},
   "source": [
    "10. Count of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fdf23014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mentions(text):\n",
    "    x = re.findall(r'(@w[A-Za-z0-9]*)', text)\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f27bcd",
   "metadata": {},
   "source": [
    "11. Count of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4a22447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # need to use the medium model (not small one)\n",
    "nlp.Defaults.stop_words -= {\"no\", \"not\", \"isn't\",\"can't\", \"cannot\", \"doesn't\", \"don't\", \"but\", \"won't\", \"shouldn't\"} #to remove words form Spacy stopwords\n",
    "\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a3fa1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'everywhere', 'here', 'off', 'back', 'seeming', 'over', 'first', 'other', 'onto', 'hundred', 'something', 'him', 'via', 'get', '’s', 'latter', 'seems', 'never', 'any', 'around', 'hereafter', 'somewhere', 'they', 'afterwards', 'often', 'otherwise', 'further', 'unless', 'we', 'call', 'until', '‘ve', 'he', 'really', 'thence', 'because', 'six', 'herself', 'ourselves', 'two', 'becomes', 'whereas', 'who', 'fifty', 'does', 'done', 'forty', 'it', \"'ve\", 'mine', 'up', 'third', 'again', 'am', 'least', 'together', 'anything', 'all', 'nine', 'be', 'and', 'into', 'give', 'could', 'else', 'between', '’re', 'towards', 'each', 'many', 'yourself', 'empty', 'side', 'latterly', 'bottom', 'front', 'must', 'hence', \"'re\", 'always', 'have', 'hereupon', 'part', 'make', 'just', 'us', 'about', 'beside', 'sixty', 'will', 'becoming', 'made', 'nevertheless', 'yet', \"'m\", 'anyway', 'after', 'due', 'became', 'before', 'much', '‘ll', 'yours', 'move', 'our', 'anyone', 'whoever', 'elsewhere', 'thru', 'been', 'them', '‘m', 'used', 'on', 'would', 'same', 'now', 'thereupon', 'eleven', 'me', 'per', 'against', 'had', 'perhaps', 'also', 'hereby', 'three', 'that', 'your', 'almost', \"'ll\", 'except', 'by', \"n't\", 'with', 'there', 'twelve', 'across', 'whether', 'someone', 'ten', 'take', 'five', 'these', 'this', 'besides', 'at', 'several', 'eight', 'indeed', 'should', 'the', 'how', 'neither', '’ll', 'yourselves', 'my', 'his', 'without', '‘re', 'whither', 'wherein', 'say', 'throughout', 'such', 'himself', 'therefore', 'well', 'above', 'four', 'since', 'n’t', 'few', 'is', 'become', 'too', 'during', 'another', 'nor', 'in', 'see', 'more', 'thereby', 'most', 'or', 'those', 'within', 'fifteen', 'twenty', 'so', 'using', 'you', 'next', 'their', 'regarding', 'thereafter', 'already', 'name', 'down', 'show', 're', 'seemed', 'which', 'last', 'upon', 'every', 'beyond', 'anyhow', 'anywhere', 'nowhere', 'thus', 'where', 'very', 'are', '’d', 'then', 'rather', 'myself', 'only', 'ours', 'toward', 'beforehand', 'either', 'might', 'moreover', 'themselves', 'therein', 'please', 'its', 'what', 'sometimes', 'some', 'both', 'if', 'through', 'others', 'i', 'nothing', 'full', 'a', 'as', 'former', 'seem', \"'d\", 'top', 'even', '‘s', 'were', 'herein', 'sometime', 'why', 'put', 'for', 'noone', 'can', 'although', 'amongst', 'behind', 'hers', 'whole', 'whereby', 'when', 'she', 'whenever', 'among', 'ca', 'alone', 'under', '‘d', 'wherever', 'itself', 'being', 'whose', 'an', 'namely', 'to', 'out', 'amount', 'own', 'quite', 'her', 'did', 'less', 'nobody', 'while', 'whence', 'along', 'enough', 'has', 'whatever', 'from', 'formerly', 'mostly', 'somehow', 'meanwhile', 'was', 'ever', 'n‘t', 'everyone', 'of', 'none', 'however', 'whom', 'various', 'than', 'doing', 'go', 'one', 'whereafter', 'everything', 'though', 'serious', 'keep', 'may', 'do', '’m', 'once', 'below', 'whereupon', \"'s\", '’ve', 'still'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9754a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(text):\n",
    "    stop_words = stopwords  \n",
    "    word_tokens = word_tokenize(text)\n",
    "    stopwords_x = [w for w in word_tokens if w in stop_words]\n",
    "    return len(stopwords_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a971a",
   "metadata": {},
   "source": [
    "11. Count of emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_emoji(text):\n",
    "    return emoji.emoji_count(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6565a",
   "metadata": {},
   "source": [
    "##### Application of 1st round of feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "105f41e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply all the functions just created above, to the whole dataset\n",
    "df['char_count'] = df[\"text\"].apply(lambda x:count_chars(x))\n",
    "df['word_count'] = df[\"text\"].apply(lambda x:count_words(x))\n",
    "df['sent_count'] = df[\"text\"].apply(lambda x:count_sent(x))\n",
    "df['capital_char_count'] = df[\"text\"].apply(lambda x:count_capital_chars(x))\n",
    "df['capital_word_count'] = df[\"text\"].apply(lambda x:count_capital_words(x))\n",
    "df['quoted_word_count'] = df[\"text\"].apply(lambda x:count_words_in_quotes(x))\n",
    "df['stopword_count'] = df[\"text\"].apply(lambda x:count_stopwords(x))\n",
    "df['unique_word_count'] = df[\"text\"].apply(lambda x:count_unique_words(x))\n",
    "df['htag_count'] = df[\"text\"].apply(lambda x:count_htags(x))\n",
    "df['mention_count'] = df[\"text\"].apply(lambda x:count_mentions(x))\n",
    "df['punct_count'] = df[\"text\"].apply(lambda x:count_punctuations(x))\n",
    "df['emoji_count'] = df[\"text\"].apply(lambda x:count_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5b9b2bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12338 entries, 0 to 12337\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   text                12338 non-null  object        \n",
      " 1   rating              12338 non-null  int64         \n",
      " 2   date                12338 non-null  datetime64[ns]\n",
      " 3   char_count          12338 non-null  int64         \n",
      " 4   word_count          12338 non-null  int64         \n",
      " 5   sent_count          12338 non-null  int64         \n",
      " 6   capital_char_count  12338 non-null  int64         \n",
      " 7   capital_word_count  12338 non-null  int64         \n",
      " 8   quoted_word_count   12338 non-null  int64         \n",
      " 9   stopword_count      12338 non-null  int64         \n",
      " 10  unique_word_count   12338 non-null  int64         \n",
      " 11  htag_count          12338 non-null  int64         \n",
      " 12  mention_count       12338 non-null  int64         \n",
      " 13  punct_count         12338 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(11), object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e5767",
   "metadata": {},
   "source": [
    "#### Step 2 => New features created directly from features above and applied on df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef197b",
   "metadata": {},
   "source": [
    "12. Calculating average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e55bb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_wordlength'] = df['char_count']/df['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53edf648",
   "metadata": {},
   "source": [
    "13. Calculating average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0976421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_sentlength'] = df['word_count']/df['sent_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fddb5f",
   "metadata": {},
   "source": [
    "14. Ratio unique words vs word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9f6ad659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unique_vs_words'] = df['unique_word_count']/df['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f604ff",
   "metadata": {},
   "source": [
    "15. Ratio stopwords count vs words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "71372423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopwords_vs_words'] = df['stopword_count']/df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e31b3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12338 entries, 0 to 12337\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   text                12338 non-null  object        \n",
      " 1   rating              12338 non-null  int64         \n",
      " 2   date                12338 non-null  datetime64[ns]\n",
      " 3   char_count          12338 non-null  int64         \n",
      " 4   word_count          12338 non-null  int64         \n",
      " 5   sent_count          12338 non-null  int64         \n",
      " 6   capital_char_count  12338 non-null  int64         \n",
      " 7   capital_word_count  12338 non-null  int64         \n",
      " 8   quoted_word_count   12338 non-null  int64         \n",
      " 9   stopword_count      12338 non-null  int64         \n",
      " 10  unique_word_count   12338 non-null  int64         \n",
      " 11  htag_count          12338 non-null  int64         \n",
      " 12  mention_count       12338 non-null  int64         \n",
      " 13  punct_count         12338 non-null  object        \n",
      " 14  avg_wordlength      12338 non-null  float64       \n",
      " 15  avg_sentlength      12338 non-null  float64       \n",
      " 16  unique_vs_words     12338 non-null  float64       \n",
      " 17  stopwords_vs_words  12338 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(11), object(2)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03f082",
   "metadata": {},
   "source": [
    "16. Adding columns based on punctuation used in each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e9d27199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'rating', 'date', 'char_count', 'word_count', 'sent_count',\n",
       "       'capital_char_count', 'capital_word_count', 'quoted_word_count',\n",
       "       'stopword_count', 'unique_word_count', 'htag_count', 'mention_count',\n",
       "       'avg_wordlength', 'avg_sentlength', 'unique_vs_words',\n",
       "       'stopwords_vs_words', '!count', '#count', '$count', '%count', '&count',\n",
       "       ''count', '(count', ')count', '*count', '+count', ',count', '-count',\n",
       "       '.count', '/count', ':count', ';count', '<count', '=count', '>count',\n",
       "       '?count', '@count', '[count', '\\count', ']count', '^count', '_count',\n",
       "       '`count', '{count', '|count', '}count', '~count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new dataframe retrieving all the different punctuation used in each text\n",
    "df_punct = pd.DataFrame(list(df.punct_count))\n",
    "\n",
    "# Merging punctuation DataFrame with main DataFrame\n",
    "df = pd.merge(df, df_punct, left_index=True, right_index=True)\n",
    "\n",
    "# Dropping \"punct_count\" column from main DataFrame\n",
    "df.drop(columns=['punct_count'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "90d95b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12338 entries, 0 to 12337\n",
      "Data columns (total 48 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   text                12338 non-null  object        \n",
      " 1   rating              12338 non-null  int64         \n",
      " 2   date                12338 non-null  datetime64[ns]\n",
      " 3   char_count          12338 non-null  int64         \n",
      " 4   word_count          12338 non-null  int64         \n",
      " 5   sent_count          12338 non-null  int64         \n",
      " 6   capital_char_count  12338 non-null  int64         \n",
      " 7   capital_word_count  12338 non-null  int64         \n",
      " 8   quoted_word_count   12338 non-null  int64         \n",
      " 9   stopword_count      12338 non-null  int64         \n",
      " 10  unique_word_count   12338 non-null  int64         \n",
      " 11  htag_count          12338 non-null  int64         \n",
      " 12  mention_count       12338 non-null  int64         \n",
      " 13  avg_wordlength      12338 non-null  float64       \n",
      " 14  avg_sentlength      12338 non-null  float64       \n",
      " 15  unique_vs_words     12338 non-null  float64       \n",
      " 16  stopwords_vs_words  12338 non-null  float64       \n",
      " 17  !count              12338 non-null  int64         \n",
      " 18  #count              12338 non-null  int64         \n",
      " 19  $count              12338 non-null  int64         \n",
      " 20  %count              12338 non-null  int64         \n",
      " 21  &count              12338 non-null  int64         \n",
      " 22  'count              12338 non-null  int64         \n",
      " 23  (count              12338 non-null  int64         \n",
      " 24  )count              12338 non-null  int64         \n",
      " 25  *count              12338 non-null  int64         \n",
      " 26  +count              12338 non-null  int64         \n",
      " 27  ,count              12338 non-null  int64         \n",
      " 28  -count              12338 non-null  int64         \n",
      " 29  .count              12338 non-null  int64         \n",
      " 30  /count              12338 non-null  int64         \n",
      " 31  :count              12338 non-null  int64         \n",
      " 32  ;count              12338 non-null  int64         \n",
      " 33  <count              12338 non-null  int64         \n",
      " 34  =count              12338 non-null  int64         \n",
      " 35  >count              12338 non-null  int64         \n",
      " 36  ?count              12338 non-null  int64         \n",
      " 37  @count              12338 non-null  int64         \n",
      " 38  [count              12338 non-null  int64         \n",
      " 39  \\count              12338 non-null  int64         \n",
      " 40  ]count              12338 non-null  int64         \n",
      " 41  ^count              12338 non-null  int64         \n",
      " 42  _count              12338 non-null  int64         \n",
      " 43  `count              12338 non-null  int64         \n",
      " 44  {count              12338 non-null  int64         \n",
      " 45  |count              12338 non-null  int64         \n",
      " 46  }count              12338 non-null  int64         \n",
      " 47  ~count              12338 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(42), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "27ab654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>capital_char_count</th>\n",
       "      <th>capital_word_count</th>\n",
       "      <th>quoted_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>htag_count</th>\n",
       "      <th>...</th>\n",
       "      <th>[count</th>\n",
       "      <th>\\count</th>\n",
       "      <th>]count</th>\n",
       "      <th>^count</th>\n",
       "      <th>_count</th>\n",
       "      <th>`count</th>\n",
       "      <th>{count</th>\n",
       "      <th>|count</th>\n",
       "      <th>}count</th>\n",
       "      <th>~count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.000000</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.528692</td>\n",
       "      <td>92.415059</td>\n",
       "      <td>17.153509</td>\n",
       "      <td>1.791863</td>\n",
       "      <td>2.129438</td>\n",
       "      <td>0.382153</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>7.404279</td>\n",
       "      <td>15.358972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.118871</td>\n",
       "      <td>103.510151</td>\n",
       "      <td>19.484878</td>\n",
       "      <td>1.297253</td>\n",
       "      <td>3.491026</td>\n",
       "      <td>1.053992</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>10.289477</td>\n",
       "      <td>15.667021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036007</td>\n",
       "      <td>0.028466</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1140.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating    char_count    word_count    sent_count  \\\n",
       "count  12338.000000  12338.000000  12338.000000  12338.000000   \n",
       "mean       4.528692     92.415059     17.153509      1.791863   \n",
       "std        1.118871    103.510151     19.484878      1.297253   \n",
       "min        1.000000      1.000000      1.000000      1.000000   \n",
       "25%        5.000000     26.000000      5.000000      1.000000   \n",
       "50%        5.000000     56.000000     10.000000      1.000000   \n",
       "75%        5.000000    115.000000     21.000000      2.000000   \n",
       "max        5.000000   1140.000000    214.000000     20.000000   \n",
       "\n",
       "       capital_char_count  capital_word_count  quoted_word_count  \\\n",
       "count        12338.000000        12338.000000       12338.000000   \n",
       "mean             2.129438            0.382153           0.000162   \n",
       "std              3.491026            1.053992           0.012731   \n",
       "min              0.000000            0.000000           0.000000   \n",
       "25%              1.000000            0.000000           0.000000   \n",
       "50%              1.000000            0.000000           0.000000   \n",
       "75%              2.000000            0.000000           0.000000   \n",
       "max            110.000000           29.000000           1.000000   \n",
       "\n",
       "       stopword_count  unique_word_count  htag_count  ...   [count  \\\n",
       "count    12338.000000       12338.000000     12338.0  ...  12338.0   \n",
       "mean         7.404279          15.358972         0.0  ...      0.0   \n",
       "std         10.289477          15.667021         0.0  ...      0.0   \n",
       "min          0.000000           1.000000         0.0  ...      0.0   \n",
       "25%          1.000000           5.000000         0.0  ...      0.0   \n",
       "50%          4.000000          10.000000         0.0  ...      0.0   \n",
       "75%          9.000000          20.000000         0.0  ...      0.0   \n",
       "max        105.000000         152.000000         0.0  ...      0.0   \n",
       "\n",
       "             \\count   ]count        ^count        _count        `count  \\\n",
       "count  12338.000000  12338.0  12338.000000  12338.000000  12338.000000   \n",
       "mean       0.000081      0.0      0.000648      0.000486      0.000081   \n",
       "std        0.009003      0.0      0.036007      0.028466      0.009003   \n",
       "min        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.0      0.000000      0.000000      0.000000   \n",
       "max        1.000000      0.0      2.000000      2.000000      1.000000   \n",
       "\n",
       "        {count   |count   }count        ~count  \n",
       "count  12338.0  12338.0  12338.0  12338.000000  \n",
       "mean       0.0      0.0      0.0      0.000162  \n",
       "std        0.0      0.0      0.0      0.012731  \n",
       "min        0.0      0.0      0.0      0.000000  \n",
       "25%        0.0      0.0      0.0      0.000000  \n",
       "50%        0.0      0.0      0.0      0.000000  \n",
       "75%        0.0      0.0      0.0      0.000000  \n",
       "max        0.0      0.0      0.0      1.000000  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52febf20",
   "metadata": {},
   "source": [
    "### B) Preprocessing methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb139ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform emojis into words\n",
    "def emo_trans(text):\n",
    "    text=emoji.demojize(text)\n",
    "    text=text.replace(\":\",\" \")\n",
    "    text=' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b234d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct mispelling words\n",
    "class Solution:\n",
    "    def solve(self, s):\n",
    "        seen = s[0]\n",
    "        ans = s[0]\n",
    "        for i in s[1:]:\n",
    "            if i != seen:\n",
    "                ans += i\n",
    "                seen = i\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = Solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e2c6b1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/vb/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(text):\n",
    "    text=text.lower() # to put in lower case\n",
    "    text=' '.join(text.split()) # to remove extra white spaces (whichever how many)\n",
    "    text=re.sub(\"'\", \"\", text) # to avoid removing contractions in english\n",
    "    text=emo_trans(text) # to transform emojis into words\n",
    "    text=re.sub(\"@[A-Za-z0-9_]+\",\"\", text) # to remove mentions\n",
    "    text=re.sub(\"#[A-Za-z0-9_]+\",\"\", text) # to remove hashtags\n",
    "    text=re.sub(r\"http\\S+\", \"\", text) # to remove urls\n",
    "    text=re.sub(r\"www.\\S+\", \"\", text) # to remove urls\n",
    "    text=re.sub('((www.[^s]+)|(https?://[^s]+))',' ',text) # to remove urls - 3rd version\n",
    "    text=re.sub(\"[^a-z0-9]\",\" \", text) # to remove non-alphanumerical characters\n",
    "    text=ob.solve(text)\n",
    "    text=correcter_words(text)\n",
    "    tokens = word_tokenize(text) # to tokenize\n",
    "    tokens_no_punctuation = [t for t in tokens if t.isalpha()]\n",
    "    tokens_no_stop = [t for t in tokens_no_punctuation if t not in stopwords]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    token_lem = [lemmatizer.lemmatize(t) for t in tokens_no_stop]\n",
    "    return token_lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18a743",
   "metadata": {},
   "source": [
    "### C) Separating reviews per rating level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d2d96528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 48)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with 1-star reviews\n",
    "df_1star = df.loc[df['rating']==1]\n",
    "df_1star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "499388b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 48)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with 2-star reviews\n",
    "df_2star = df.loc[df['rating']==2]\n",
    "df_2star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bcb9bbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 48)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with 3-star reviews\n",
    "df_3star = df.loc[df['rating']==3]\n",
    "df_3star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4faeb7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 48)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with 4-star reviews\n",
    "df_4star = df.loc[df['rating']==4]\n",
    "df_4star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d06383ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9939, 48)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df with 5-star reviews\n",
    "df_5star = df.loc[df['rating']==5]\n",
    "df_5star.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e4376",
   "metadata": {},
   "source": [
    "### D) Preprocessing per rating level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f3782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de926d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb2464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb8ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2580c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8268bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbb736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c37a3c1",
   "metadata": {},
   "source": [
    "### E) TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e192499",
   "metadata": {},
   "source": [
    "extracting features from text is to use the bag of words model: a model where for each document, a complaint narrative in our case, the presence (and often the frequency) of words is taken into consideration, but the order in which they occur is ignored.\n",
    "\n",
    "Specifically, for each term in our dataset, we will calculate a measure called Term Frequency, Inverse Document Frequency, abbreviated to tf-idf. We will use sklearn.feature_extraction.text.TfidfVectorizer to calculate a tf-idf vector for each of consumer complaint narratives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 4), stop_words='english')\n",
    "features = tfidf.fit_transform(df_test1['review_content']).toarray()\n",
    "labels = df_test1['rating']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f079d",
   "metadata": {},
   "source": [
    "Now, each of 22968 consumer reviews narratives is represented by 8728 features, representing the tf-idf score for different unigrams and bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af641df0",
   "metadata": {},
   "source": [
    "### F) N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96a2f4",
   "metadata": {},
   "source": [
    "We can use sklearn.feature_selection.chi2 to find the terms that are the most correlated with each of the rating_label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feda68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5 #top x associated words to be displayed\n",
    "for rating_label, rating in sorted(ratinglabel_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == rating)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names_out())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "    quadrigrams = [v for v in feature_names if len(v.split(' ')) == 4]\n",
    "    print(\"# '{}' star :\".format(rating))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "    print(\"  . Most correlated trigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))\n",
    "    print(\"  . Most correlated quadrigrams:\\n. {}\".format('\\n. '.join(quadrigrams[-N:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a33a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61430f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f7c779",
   "metadata": {},
   "source": [
    "### G) Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8119b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf825cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ce9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2337f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7a163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d09255a",
   "metadata": {},
   "source": [
    "# Phase 2 => Topic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30a608",
   "metadata": {},
   "source": [
    "### Step 1 - Dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b78aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09430d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ed16443",
   "metadata": {},
   "source": [
    "### Step 2 - Dataset splitting between train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28b00086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    80.556006\n",
       "4     7.440428\n",
       "1     6.759604\n",
       "3     3.079916\n",
       "2     2.164046\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating distribution \n",
    "df['rating'].value_counts()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1121a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"rating\", axis = 1)\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9face3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7402, 2)\n",
      "X_test shape: (2468, 2)\n",
      "y_train shape: (7402,)\n",
      "y_test shape: (2468,)\n",
      "X_val shape: (2468, 2)\n",
      "y_val shape: (2468,)\n"
     ]
    }
   ],
   "source": [
    "# set aside 20% of train and test data for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify= y, test_size=0.2, shuffle = True, \n",
    "                                                    random_state = 8)\n",
    "\n",
    "# Use the same function above for the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify= y_train, test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y_val shape: {}\".format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5958d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    80.559308\n",
       "4     7.430424\n",
       "1     6.754931\n",
       "3     3.080249\n",
       "2     2.175088\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/y_train.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b63e265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    80.551053\n",
       "4     7.455429\n",
       "1     6.766613\n",
       "3     3.079417\n",
       "2     2.147488\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/y_test.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e274f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    80.551053\n",
       "4     7.455429\n",
       "1     6.766613\n",
       "3     3.079417\n",
       "2     2.147488\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()/y_val.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793bab0f",
   "metadata": {},
   "source": [
    "### Step 3 - ML Classifications applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5536a",
   "metadata": {},
   "source": [
    "We are now ready to experiment with different machine learning models, evaluate their accuracy and find the source of any potential issues.\n",
    "\n",
    "We will benchmark the following 5 models:\n",
    "\n",
    "- Logistic Regression\n",
    "- (Multinomial) Naive Bayes\n",
    "- Linear Support Vector Machine\n",
    "- Random Forest\n",
    "- K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc69fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    KNeighborsClassifier(n_neighbors = 5),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "CV = 5 #nb of model\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "        \n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e906f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf0f939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855680c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3788a55d",
   "metadata": {},
   "source": [
    "### Step 4 - Performance ML Classification models comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bb0c69",
   "metadata": {},
   "source": [
    "2 models seem to perform well : SVC & Logistic regression.\n",
    "We are going to look deeper in their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab531eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC() \n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val, indices_train, indices_val = train_test_split(features, labels, df.index, test_size=0.2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=rating_df['rating'].values, yticklabels=rating_df['rating'].values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression()\n",
    "#X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df_test1.index, test_size=0.2, random_state=0)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "conf_mat2 = confusion_matrix(y_test, y_pred2)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=rating_df['rating_label'].values, yticklabels=rating_df['rating_label'].values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f80bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c280847",
   "metadata": {},
   "source": [
    "**Conclusion** => best ML is SVC. So this will be applied on Twitter reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1043e2",
   "metadata": {},
   "source": [
    "# Phase 3 => Application on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4feb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
